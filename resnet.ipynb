{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4fMJpuKc49V"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "root_path = \"/content/drive/MyDrive/Colab Notebooks/project\"\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.chdir(root_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Mc_Be35c8cx"
      },
      "outputs": [],
      "source": [
        "!pwd\n",
        "!mkdir dowload\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_-iYNzVdC-V"
      },
      "outputs": [],
      "source": [
        "!pip install spotdl\n",
        "!pip install tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hemGWb8RdK-A"
      },
      "outputs": [],
      "source": [
        "# download splited list\n",
        "import os\n",
        "import pandas as pd\n",
        "# import spotdl\n",
        "\n",
        "# TODO modify .csv path\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/project/music_genre.csv\",index_col=0, header=[0])\n",
        "df.reset_index(inplace=True)\n",
        "# df.columns.values\n",
        "\n",
        "id_to_title = {k: v for k, v in zip( df.instance_id.to_list(), df.track_name.to_list() )}\n",
        "\n",
        "data = {\n",
        "  k: v\n",
        "  for k, v in zip(df[\"instance_id\"].tolist(), df[\"popularity\"].tolist())\n",
        "}\n",
        "\n",
        "download_list = df.track_name.to_list()\n",
        "\n",
        "download_splited_list = [\n",
        " download_list[x:x+100] for x in range(0, len(download_list), 100)\n",
        "]\n",
        "print(len(download_splited_list))\n",
        "print(len(download_list))\n",
        "\n",
        "# TODO modify path\n",
        "spotify_dir = \"/content/drive/MyDrive/Colab Notebooks/project/dowload\"\n",
        "\n",
        "cnt = 37\n",
        "for splited_list in download_splited_list[36:500]:\n",
        "    os.chdir(spotify_dir)\n",
        "    dir_name = str(cnt).zfill(3)\n",
        "\n",
        "    cmd = \"mkdir \" + dir_name\n",
        " # print(cmd)\n",
        "    os.system(cmd)\n",
        " \n",
        "    os.chdir( os.path.join(spotify_dir, dir_name) )\n",
        " \n",
        "    os.system(\"pwd\")\n",
        " \n",
        "    print(\"Now downloading list\", dir_name, \":\", len(splited_list))\n",
        "    for song in splited_list:\n",
        "        cmd = \"spotdl download \" + \"'\" + song + \"'\" + \" --output {title}\"\n",
        "        print(cmd)\n",
        "        # cmd = \"spotdl download \" + \"'\" + song + \"'\" + \" --output {title}\"\n",
        "        os.system(cmd)\n",
        "        # break\n",
        "\n",
        "# cmd = \"spotdl download\" +\" 'Shape of you'\"+ \" 'Closer'\" + \" --output {title}\"\n",
        "\n",
        "    cnt += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkH7GrbgTVzp"
      },
      "outputs": [],
      "source": [
        "!pip install torchaudio\n",
        "import torch\n",
        "import torchvision\n",
        "import torchaudio\n",
        "import random\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "%matplotlib inline\n",
        "from tqdm.autonotebook import tqdm\n",
        "import IPython.display as ipd\n",
        "import torchvision.transforms as T\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lf-RDAx3XaZB"
      },
      "outputs": [],
      "source": [
        "img_path = 'img_data7'\n",
        "df = pd.read_csv(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/project/data_merged.csv')\n",
        "diction = dict(zip(df['track_name'],df['popularity']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpVmWt3tITqc"
      },
      "outputs": [],
      "source": [
        "def random_crop(data, crop_size=22050*25):\n",
        "  start = np.random.randint(0, len(data) - crop_size)\n",
        "  return data[start : (start + crop_size)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByiI0WXGXkTT"
      },
      "outputs": [],
      "source": [
        "cmap = plt.get_cmap('inferno')\n",
        "plt.figure(figsize=(8,8))\n",
        "minduration = 240\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/project/dowload\")\n",
        "# genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
        "# for root,dirs,files in os.walk(\"/content/drive/MyDrive/Colab Notebooks/project/dowload\"):\n",
        "#       for dirc in dirs:\n",
        "#         os.chdir(f'/content/drive/MyDrive/Colab Notebooks/project/dowload/{dirc}')\n",
        "#         for _,_,file1 in os.walk(f'/content/drive/MyDrive/Colab Notebooks/project/dowload/{dirc}'):\n",
        "#           for file in file1:\n",
        "#             # cmd = \"mkdir \" + os.path.join('popularity_img', 'pop')\n",
        "#             y, sr = librosa.load(file)\n",
        "#             # pathlib.Path(f'/content/drive/MyDrive/Colab Notebooks/project/img_data1/{pop}').mkdir(parents=True, exist_ok=True) \n",
        "#             duration = librosa.get_duration(y=y)\n",
        "#             if duration < minduration:\n",
        "#               minduration = duration\n",
        "# print(minduration)\n",
        "\n",
        "\n",
        "for root,dirs,files in os.walk(\"/content/drive/MyDrive/Colab Notebooks/project/dowload\"):\n",
        "      for dirc in dirs:\n",
        "        os.chdir(f'/content/drive/MyDrive/Colab Notebooks/project/dowload/{dirc}')\n",
        "        for _,_,file1 in os.walk(f'/content/drive/MyDrive/Colab Notebooks/project/dowload/{dirc}'):\n",
        "          for file in file1:\n",
        "            pop = str(diction.get(file[:-4]))\n",
        "            if pop != 'None':\n",
        "\n",
        "            # cmd = \"mkdir \" + os.path.join('popularity_img', 'pop')\n",
        "              pathlib.Path(f'/content/drive/MyDrive/Colab Notebooks/project/{img_path}/{pop}').mkdir(parents=True, exist_ok=True)\n",
        "            \n",
        "              y, sr = librosa.load(file,sr=22050, mono=True)\n",
        "              for i in range(0,3):\n",
        "                print(f'now is {file}/{i}')\n",
        "                # print(len(y))\n",
        "                sample = random_crop(y)\n",
        "                plt.specgram(sample, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
        "                plt.axis('off');\n",
        "                plt.savefig(f'/content/drive/MyDrive/Colab Notebooks/project/{img_path}/{pop}/{file[:-3].replace(\".\", \"\")}_{i}.png');\n",
        "                plt.clf()\n",
        "        # os.system(cmd)\n",
        "# for g in genres:\n",
        "#   pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)\n",
        "#   for filename in os.listdir(f'{data_path}/{g}'):\n",
        "#     songname = f'{data_path}/{g}/{filename}'\n",
        "#     y, sr = librosa.load(songname, mono=True, duration=5)\n",
        "#     plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
        "#     plt.axis('off');\n",
        "#     plt.savefig(f'img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
        "#     plt.clf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN1Kbw_c7hLy",
        "outputId": "4b728219-6f2b-408d-d9f5-ea0a0798abdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/project\n",
            "rm: cannot remove 'f/content/drive/MyDrive/Colab Notebooks/project/img_path/None': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# os.chdir(f'/content/drive/MyDrive/Colab Notebooks/project/{img_path}')\n",
        "!pwd\n",
        "# cmd = \"rm\" + \"-r\" + f\"/content/drive/MyDrive/Colab Notebooks/project/{img_path}/None\"\n",
        "# os.system(cmd)\n",
        "!rm -r f'/content/drive/MyDrive/Colab Notebooks/project/'img_path'/None'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ekmPezOXkVZ"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZdBkb8zXkX6"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "image_size = 224\n",
        "train_trms = T.Compose([\n",
        "                        T.Resize(image_size),\n",
        "                        T.RandomRotation(20),\n",
        "                        T.RandomHorizontalFlip(),\n",
        "                        T.ToTensor()\n",
        "                        ])\n",
        "val_trms = T.Compose([\n",
        "                        T.Resize(image_size),\n",
        "                        T.ToTensor()\n",
        "                        ])\n",
        "train_data = torchvision.datasets.ImageFolder(root = f'/content/drive/MyDrive/Colab Notebooks/project/{img_path}', transform = train_trms)\n",
        "print(len(train_data))\n",
        "val_data = torchvision.datasets.ImageFolder(root = f'/content/drive/MyDrive/Colab Notebooks/project/{img_path}', transform = val_trms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaofXassfdDG"
      },
      "outputs": [],
      "source": [
        "def Encode(data):\n",
        "    classes = data.classes\n",
        "    encoder = {}\n",
        "    for i in range(len(classes)):\n",
        "        encoder[i] = classes[i]\n",
        "    return encoder\n",
        "\n",
        "def Decoder(data):\n",
        "    classes = data.classes\n",
        "    \n",
        "    decoder = {}\n",
        "    for i in range(len(classes)):\n",
        "        decoder[classes[i]] = i\n",
        "    return decoder\n",
        "    \n",
        "def class_plot(data,n_figures =12):\n",
        "    n_row = int(n_figures/4)\n",
        "    fig,axes = plt.subplots(figsize=(14, 10), nrows = n_row, ncols=4)\n",
        "    for ax in axes.flatten():\n",
        "        a = random.randint(0,len(data))\n",
        "        (image,label) = data[a]\n",
        "#         print(type(image))\n",
        "        label = int(label)\n",
        "        encoder = Encode(data)\n",
        "        l = encoder[label]\n",
        "       \n",
        "        image = image.numpy().transpose(1,2,0)\n",
        "        im = ax.imshow(image)\n",
        "        ax.set_title(l)\n",
        "        ax.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqkU1uzSfdKS"
      },
      "outputs": [],
      "source": [
        "class_plot(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YcIVfk7fl02"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(43)\n",
        "val_size = int(len(train_data)*0.1)\n",
        "train_size = len(train_data) - val_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cqIMcGJfl6Y",
        "outputId": "bc51aed9-e1c4-42d9-b918-76de376a1887"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "train_ds, val_ds = random_split(train_data, [train_size,val_size])\n",
        "len(train_ds), len(val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8ubLBPUfl8J",
        "outputId": "4a68400f-9275-42a9-c380-0770aceb43c0"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "print(len(train_dl))\n",
        "val_dl = DataLoader(val_ds, batch_size*2, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aKIOkqwfmA0"
      },
      "outputs": [],
      "source": [
        "for images, _ in train_dl:\n",
        "    print('images.shape:', images.shape)\n",
        "    plt.figure(figsize=(16,8))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXimI2XAfuRL"
      },
      "outputs": [],
      "source": [
        "def accuracy(outputs, labels):\n",
        "\n",
        "  _,preds = torch.max(outputs,dim=1)\n",
        "  return torch.tensor(torch.sum(preds == labels).item()/len(preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dbDgInQfuWp"
      },
      "outputs": [],
      "source": [
        "class MultilabelImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, targets = batch \n",
        "        out = self(images)                      \n",
        "        loss = F.cross_entropy(out, targets)      \n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, targets = batch \n",
        "        print(len(batch))\n",
        "        print(targets)\n",
        "        class_plot(batch)\n",
        "        out = self(images)                           # Generate predictions\n",
        "        loss = F.cross_entropy(out, targets)  # Calculate loss\n",
        "        score = accuracy(out, targets)\n",
        "        print(score)\n",
        "        return {'val_loss': loss.detach(), 'val_score': score.detach() }\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_scores = [x['val_score'] for x in outputs]\n",
        "        epoch_score = torch.stack(batch_scores).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_score': epoch_score.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_score: {:.4f}\".format(\n",
        "            epoch, result['val_loss'], result['val_score']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAQ5e-SRfuZO"
      },
      "outputs": [],
      "source": [
        "class Net1(MultilabelImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "\n",
        "            nn.Flatten(), \n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 4)\n",
        "            \n",
        "        )\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WciZOqnfudf"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "class Net(MultilabelImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Use a pretrained model\n",
        "        self.network = models.resnet34(pretrained=True)\n",
        "        # Replace last layer\n",
        "        num_ftrs = self.network.fc.in_features\n",
        "        self.network.fc = nn.Linear(num_ftrs, 4)\n",
        "    \n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)\n",
        "    def freeze(self):\n",
        "      for param in self.network.parameters():\n",
        "        param.require_grad = False\n",
        "      for param in self.network.fc.parameters():\n",
        "        param.require_grad = True\n",
        "    \n",
        "    def unfreeze(self):\n",
        "      for param in self.network.parameters():\n",
        "        param.require_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0YFaIfuf62I"
      },
      "outputs": [],
      "source": [
        "Net()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Rbv5Ewlf8Jc"
      },
      "outputs": [],
      "source": [
        "def evaluate(model,val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]    \n",
        "    return model.validation_epoch_end(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8goy7YUdf96Z"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
        "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "    # Set up cutom optimizer with weight decay\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    # Set up one-cycle learning rate scheduler\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        lrs = []\n",
        "        for batch in tqdm(train_loader):\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            # Gradient clipping\n",
        "            if grad_clip: \n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            # Record & update learning rate\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGCCBSbef99q"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FEmNTFKf9_p"
      },
      "outputs": [],
      "source": [
        "device = get_default_device()\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OItHsQ2gG8_"
      },
      "outputs": [],
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hLy_CUlgG-k"
      },
      "outputs": [],
      "source": [
        "model = to_device(Net(), device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VPTx4WigHAV"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "524a29MxgHCk"
      },
      "outputs": [],
      "source": [
        "history = [evaluate(model, val_dl)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTKIj3KJgHEX"
      },
      "outputs": [],
      "source": [
        "model.freeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fj0DcrDogHGT"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "max_lr = 0.001\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-5\n",
        "opt_func = torch.optim.Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao7IKZGjgxLC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdYnnrMTgxNR"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "history += fit_one_cycle(15, max_lr, model, train_dl, val_dl, \n",
        "                         grad_clip=grad_clip, \n",
        "                         weight_decay=weight_decay, \n",
        "                         opt_func=opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A44_gKAnhDRp"
      },
      "outputs": [],
      "source": [
        "model.unfreeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7zWgmp5hDg2"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "history += fit_one_cycle(50, max_lr, model, train_dl, val_dl, \n",
        "                         grad_clip=grad_clip, \n",
        "                         weight_decay=weight_decay, \n",
        "                         opt_func=opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mW2VzAzohDjB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sZr6rPmhILQ"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), '/content/model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuOMW3toXkaN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDVeF52KXkff"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qpAkRcTYA_A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7x7MtjDYJiq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
